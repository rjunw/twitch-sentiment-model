{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00GDvCJucnpv"
      },
      "source": [
        "# Install HuggingFace Transformers package with the pretrained BERT models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FVGNcwsowF-",
        "outputId": "cf5cce7d-4eb6-4c97-b0c7-25478f39ca36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AIe26NRcuYZ",
        "outputId": "9cf232b9-a3fb-4283-9961-631faf2e7ca5"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers emoji datasets gensim\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntdi6Jep44G2"
      },
      "source": [
        "# Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3rE2WMH5-oB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PFUHtDp6FMu"
      },
      "source": [
        "# Runtime environment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkGc79g2c3DL",
        "outputId": "165a7d7f-6ef0-4430-cea5-e5377cbceded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McMxFa1MQi_Y"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uowKTzkr6pkj"
      },
      "source": [
        "# Loading Twitch dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlO6Ywyf28l1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "def train_valid_split_w2v(input_ids, input_w2v, attention_masks, labels, batch_size=32):\n",
        "    \"\"\"\n",
        "    Create DataLoader objects for downstream training\n",
        "    \"\"\"\n",
        "    # Use 80% for training and 20% for validation.\n",
        "    train_inputs, validation_inputs, train_w2v, validation_w2v, train_masks, validation_masks, train_labels, validation_labels = train_test_split(\n",
        "        input_ids, input_w2v, attention_masks, labels, random_state=SEED, test_size=0.2, stratify=labels\n",
        "    )\n",
        "\n",
        "    print('example train_input:    ', train_inputs[0])\n",
        "    print('example attention_mask: ', train_masks[0])\n",
        "\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "    # Create the DataLoader for our training set.\n",
        "    train_data = TensorDataset(train_inputs, train_w2v, train_masks, train_labels)\n",
        "\n",
        "    train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "    # Create the DataLoader for our validation set.\n",
        "    validation_data = TensorDataset(validation_inputs, validation_w2v, validation_masks, validation_labels)\n",
        "    validation_dataloader = DataLoader(validation_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, validation_dataloader\n",
        "\n",
        "def train_valid_split_w2v_ext(input_ids, input_w2v, ext_w2v, attention_masks, labels, batch_size=32):\n",
        "    \"\"\"\n",
        "    Create DataLoader objects for downstream training\n",
        "    \"\"\"\n",
        "    # Use 80% for training and 20% for validation.\n",
        "    train_inputs, validation_inputs, train_w2v, validation_w2v, train_ext, validation_ext, train_masks, validation_masks, train_labels, validation_labels = train_test_split(\n",
        "        input_ids, input_w2v, ext_w2v, attention_masks, labels, random_state=SEED, test_size=0.2, stratify=labels\n",
        "    )\n",
        "\n",
        "    print('example train_input:    ', train_inputs[0])\n",
        "    print('example attention_mask: ', train_masks[0])\n",
        "\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "    # Create the DataLoader for our training set.\n",
        "    train_data = TensorDataset(train_inputs, train_w2v, train_ext, train_masks, train_labels)\n",
        "\n",
        "    train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "    # Create the DataLoader for our validation set.\n",
        "    validation_data = TensorDataset(validation_inputs, validation_w2v, validation_ext, validation_masks, validation_labels)\n",
        "    validation_dataloader = DataLoader(validation_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, validation_dataloader\n",
        "\n",
        "def train_valid_split_ext(input_ids, input_ext, attention_masks, labels, seed, batch_size=32):\n",
        "    \"\"\"\n",
        "    Create DataLoader objects for downstream training\n",
        "    input_ext: any additional embeddings\n",
        "    \"\"\"\n",
        "    # Use 80% for training and 20% for validation.\n",
        "    train_inputs, validation_inputs, train_ext, validation_ext, train_masks, validation_masks, train_labels, validation_labels = train_test_split(\n",
        "        input_ids, input_ext, attention_masks, labels, random_state=seed, test_size=0.2, stratify=labels\n",
        "    )\n",
        "\n",
        "    print('example train_input:    ', train_inputs[0])\n",
        "    print('example attention_mask: ', train_masks[0])\n",
        "\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "    # Create the DataLoader for our training set.\n",
        "    train_data = TensorDataset(train_inputs, train_ext, train_masks, train_labels)\n",
        "\n",
        "    train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "    # Create the DataLoader for our validation set.\n",
        "    validation_data = TensorDataset(validation_inputs, validation_ext, validation_masks, validation_labels)\n",
        "    validation_dataloader = DataLoader(validation_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, validation_dataloader\n",
        "\n",
        "\n",
        "def train_valid_split(input_ids, attention_masks, labels, batch_size=32):\n",
        "    # Use 80% for training and 20% for validation.\n",
        "    train_inputs, validation_inputs,  train_masks, validation_masks, train_labels, validation_labels = train_test_split(\n",
        "        input_ids, attention_masks, labels, random_state=SEED, test_size=0.2, stratify=labels\n",
        "    )\n",
        "\n",
        "    print('example train_input:    ', train_inputs[0])\n",
        "    print('example attention_mask: ', train_masks[0])\n",
        "\n",
        "    train_labels = torch.tensor(train_labels)\n",
        "    validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "    # Create the DataLoader for our training set.\n",
        "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "    train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "    # Create the DataLoader for our validation set.\n",
        "    validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "    validation_dataloader = DataLoader(validation_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, validation_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOWWv7C7Jo0H"
      },
      "source": [
        "# Training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEe1oy0AJdKC"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "import time\n",
        "import datetime\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "\n",
        "def collect_flat_outputs(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return pred_flat, labels_flat\n",
        "    \n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat, labels_flat = collect_flat_outputs(preds, labels)\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def get_optimizer_and_scheduler(model, total_steps, lr=2e-5, weight_decay=0.01):\n",
        "    # Apply weight decay to all parameters beside the biases or LayerNorm weights\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            'weight_decay': weight_decay},\n",
        "        {\n",
        "            'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            'weight_decay': 0.0\n",
        "        }\n",
        "    ]\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        # Warmup learning rate for first 10% of training steps\n",
        "        num_warmup_steps=int(0.10 * total_steps), \n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "    return optimizer, scheduler\n",
        "\n",
        "def train_model(model,\n",
        "                epochs,\n",
        "                train_dataloader,\n",
        "                validation_dataloader,\n",
        "                early_stopping_patience = 25):\n",
        "    # Use GPU, if available\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device) # TPU right now\n",
        "\n",
        "    # Setup optimizer and LR scheduler \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    optimizer, scheduler = get_optimizer_and_scheduler(\n",
        "        model, total_steps, lr = 2e-5, weight_decay = 0.1\n",
        "    )\n",
        "\n",
        "    eval_metrics = {\n",
        "            'train_loss': [],\n",
        "            'valid_loss': [],\n",
        "            'valid_accs': [],\n",
        "            'f1': [],\n",
        "            'recall': [],\n",
        "            'curr_max' : 0\n",
        "        }\n",
        "\n",
        "    #loss_values = []\n",
        "    #eval_accs = []\n",
        "    curr_max = 0 # current max eval acc\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "        t0 = time.time()\n",
        "\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        # ================== ONE EPOCH TRAINING STARTS =========================\n",
        "        with tqdm(train_dataloader, unit=\"batch\") as train_pbar:\n",
        "            for batch in train_pbar:\n",
        "                train_pbar.set_description(f\"Training (epoch {epoch + 1})\")\n",
        "                b_input_ids  = batch[0].to(device)\n",
        "                b_input_mask = batch[-2].to(device)\n",
        "                b_labels     = batch[-1].to(device)\n",
        "\n",
        "                model.zero_grad()        \n",
        "\n",
        "                # Perform a forward pass (evaluate the model on this training batch).\n",
        "                # This will return the loss because we have provided the `labels`.\n",
        "                if model.ext_embed_mode == 'GRU':\n",
        "                    b_input_add_embed = batch[1].to(device)\n",
        "                    outputs = model(\n",
        "                        input_ids      = b_input_ids, \n",
        "                        attention_mask = b_input_mask, \n",
        "                        labels         = b_labels,\n",
        "                        ext_embed_add  = b_input_add_embed\n",
        "                    )\n",
        "                elif model.ext_embed_mode == 'concat':\n",
        "                    b_input_cat_embed = batch[1].to(device)\n",
        "                    outputs = model(\n",
        "                        input_ids        = b_input_ids, \n",
        "                        attention_mask   = b_input_mask, \n",
        "                        labels           = b_labels,\n",
        "                        ext_embed_concat = b_input_cat_embed\n",
        "                    )\n",
        "                else:\n",
        "                    ## No external embedding blending in\n",
        "                    outputs = model(\n",
        "                        input_ids      = b_input_ids, \n",
        "                        attention_mask = b_input_mask, \n",
        "                        labels         = b_labels\n",
        "                    )\n",
        "                \n",
        "                # The call to `model` always returns a tuple, so we need to pull the \n",
        "                # loss value out of the tuple.\n",
        "                _, loss = outputs\n",
        "\n",
        "                # Accumulate the training loss over all of the batches so that we can\n",
        "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                # single value; the `.item()` function just returns the Python value \n",
        "                # from the tensor.\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "                # Perform a backward pass to calculate the gradients.\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip the norm of the gradients to 1.0.\n",
        "                # This is to help prevent the \"exploding gradients\" problem.\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "                # Update parameters and take a step using the computed gradient.\n",
        "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                # modified based on their gradients, the learning rate, etc.\n",
        "                optimizer.step()\n",
        "\n",
        "                # Update the learning rate.\n",
        "                scheduler.step()\n",
        "        # =================== ONE EPOCH TRAINING ENDS ==========================\n",
        "\n",
        "        # Calculate the average loss over the training data.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        \n",
        "        # Store the loss value for plotting the learning curve.\n",
        "        eval_metrics[\"train_loss\"].append(avg_train_loss)\n",
        "\n",
        "        print(\"  * Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  * Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "            \n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "        model.eval()\n",
        "\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "        f1 = 0\n",
        "        epoch_preds, epoch_labels = [], []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        # ================== ONE EPOCH VALIDATING STARTS =======================\n",
        "        for batch in validation_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids  = batch[0]\n",
        "            b_input_mask = batch[-2]\n",
        "            b_labels     = batch[-1]\n",
        "            \n",
        "            with torch.no_grad():        \n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # Perform a forward pass (evaluate the model on this training batch).\n",
        "                # This will return the loss because we have provided the `labels`.\n",
        "                if model.ext_embed_mode == 'GRU':\n",
        "                    b_input_add_embed = batch[1]\n",
        "                    outputs = model(\n",
        "                        input_ids      = b_input_ids, \n",
        "                        attention_mask = b_input_mask, \n",
        "                        labels         = b_labels,\n",
        "                        ext_embed_add  = b_input_add_embed\n",
        "                    )\n",
        "                elif model.ext_embed_mode == 'concat':\n",
        "                    b_input_cat_embed = batch[1]\n",
        "                    outputs = model(\n",
        "                        input_ids        = b_input_ids, \n",
        "                        attention_mask   = b_input_mask, \n",
        "                        labels           = b_labels,\n",
        "                        ext_embed_concat = b_input_cat_embed\n",
        "                    )\n",
        "                else:\n",
        "                    ## No external embedding blending in\n",
        "                    outputs = model(\n",
        "                        input_ids      = b_input_ids, \n",
        "                        attention_mask = b_input_mask, \n",
        "                        labels         = b_labels\n",
        "                    )\n",
        "            \n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            logits, loss = outputs\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            # Calculate the accuracy for this batch of test sentences.\n",
        "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "            # Collect predictions and labels from each validation batch\n",
        "            batch_preds, batch_labels = collect_flat_outputs(logits, label_ids)\n",
        "            epoch_preds.append(batch_preds)\n",
        "            epoch_labels.append(batch_labels)\n",
        "            # Accumulate the total accuracy.\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            # Accumulate the total loss.\n",
        "            eval_loss += loss.item()\n",
        "            # Track the number of batches\n",
        "            nb_eval_steps += 1\n",
        "        # =================== ONE EPOCH VALIDATING ENDS ========================\n",
        "        epoch_preds  = np.concatenate(epoch_preds)\n",
        "        epoch_labels = np.concatenate(epoch_labels)\n",
        "        f1 = f1_score(epoch_preds, epoch_labels, average = 'macro')\n",
        "        recall = recall_score(epoch_preds, epoch_labels, average = 'macro')\n",
        "        avg_eval_acc  = eval_accuracy / nb_eval_steps\n",
        "        avg_eval_loss = eval_loss / nb_eval_steps ## average valid. loss over batches\n",
        "        print(\"  * Accuracy: {0:.2f}\".format(avg_eval_acc))\n",
        "        print(\"  * Averaged validation loss: {0:.2f}\".format(avg_eval_loss))\n",
        "        print(\"  * F1 score: {0:.2f}\".format(f1))\n",
        "        print(\"  * Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "        eval_metrics[\"valid_accs\"].append(avg_eval_acc)\n",
        "        eval_metrics[\"valid_loss\"].append(avg_eval_loss)\n",
        "        eval_metrics['f1'].append(f1)\n",
        "        eval_metrics['recall'].append(recall)\n",
        "\n",
        "        print(f\"PREVIOUS BEST EVAL:{curr_max}\")\n",
        "        # save max eval model\n",
        "        if max(avg_eval_acc, curr_max) == avg_eval_acc:\n",
        "          curr_max = avg_eval_acc\n",
        "          eval_metrics[\"curr_max\"] = curr_max\n",
        "          try:\n",
        "            os.makedirs(\"./weights/\")\n",
        "          except:\n",
        "            print(\"dir exists\")\n",
        "          print(\"Saving Weights...\")\n",
        "          model.save_pretrained(\"./weights/curr\")\n",
        "        \n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    return eval_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_-x6PsL8SZt"
      },
      "source": [
        "## Download Twitch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43pTspoR6tPJ",
        "outputId": "8a8641fd-317f-4fc4-bb87-461be8417b7f"
      },
      "outputs": [],
      "source": [
        "!pip install gitpython\n",
        "import git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN77phG-f3DY",
        "outputId": "51cbbdbb-b13c-49a2-fd90-adcbe855cd03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already downloaded training data\n"
          ]
        }
      ],
      "source": [
        "# The URL for data Github repo.\n",
        "url = 'https://github.com/konstantinkobs/emote-controlled.git'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if os.path.exists('./emote-controlled'):\n",
        "    print('Already downloaded training data')\n",
        "else:\n",
        "    git.Git(\"./\").clone(url)\n",
        "    print('Done downloading training data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc-bxjzI-81h"
      },
      "source": [
        "## Load labeled Twitch messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "ovSDN8kBf_zF",
        "outputId": "5a7ff498-f38f-4e1b-86ea-a455bb9af376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labeled messages:  1922\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fd484f17-eae3-4dd4-b66c-af3d8abc4685\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>date</th>\n",
              "      <th>channel</th>\n",
              "      <th>game</th>\n",
              "      <th>user</th>\n",
              "      <th>mod</th>\n",
              "      <th>subscriber</th>\n",
              "      <th>message</th>\n",
              "      <th>sentiment_relevel</th>\n",
              "      <th>message_uncased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>0</td>\n",
              "      <td>2018-05-22T03:21:17.481Z</td>\n",
              "      <td>xqcow</td>\n",
              "      <td>Overwatch</td>\n",
              "      <td>2475329</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>POG</td>\n",
              "      <td>1</td>\n",
              "      <td>pog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1623</th>\n",
              "      <td>1</td>\n",
              "      <td>2018-05-16T19:32:55.000Z</td>\n",
              "      <td>forsen</td>\n",
              "      <td>The Council</td>\n",
              "      <td>2342940</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>ALLO ZULUL</td>\n",
              "      <td>2</td>\n",
              "      <td>allo zulul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>-1</td>\n",
              "      <td>2018-05-17T16:56:40.391Z</td>\n",
              "      <td>moonmoon_ow</td>\n",
              "      <td>Dark Souls III</td>\n",
              "      <td>226947</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>I WAS DANCING TO THAT DansGame</td>\n",
              "      <td>0</td>\n",
              "      <td>i was dancing to that dansgame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>1</td>\n",
              "      <td>2018-05-03T16:36:44.324Z</td>\n",
              "      <td>forsen</td>\n",
              "      <td>IRL</td>\n",
              "      <td>9000</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>gachiBASS Clap gachiBASS Clap gachiBASS Clap g...</td>\n",
              "      <td>2</td>\n",
              "      <td>gachibass clap gachibass clap gachibass clap g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1</td>\n",
              "      <td>2018-05-09T04:59:17.521Z</td>\n",
              "      <td>xqcow</td>\n",
              "      <td>Fortnite</td>\n",
              "      <td>295331</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>gachiBASS</td>\n",
              "      <td>2</td>\n",
              "      <td>gachibass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1075</th>\n",
              "      <td>1</td>\n",
              "      <td>2018-05-28T19:40:05.478Z</td>\n",
              "      <td>sodapoppin</td>\n",
              "      <td>Bless Online</td>\n",
              "      <td>322720</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>\"Premium Membership (180 Days)\" gives 8 in-gam...</td>\n",
              "      <td>2</td>\n",
              "      <td>\"premium membership (180 days)\" gives 8 in-gam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>1</td>\n",
              "      <td>2018-05-23T21:40:22.218Z</td>\n",
              "      <td>forsen</td>\n",
              "      <td>Raft</td>\n",
              "      <td>304456</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>forsen1</td>\n",
              "      <td>2</td>\n",
              "      <td>forsen1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>1</td>\n",
              "      <td>2018-05-30T19:02:31.082Z</td>\n",
              "      <td>forsen</td>\n",
              "      <td>Dark Souls</td>\n",
              "      <td>971480</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>CURSED OMEGALUL CURSED OMEGALUL CURSED OMEGALUL</td>\n",
              "      <td>2</td>\n",
              "      <td>cursed omegalul cursed omegalul cursed omegalul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>-1</td>\n",
              "      <td>2018-05-21T16:26:58.802Z</td>\n",
              "      <td>moonmoon_ow</td>\n",
              "      <td>Dark Souls III</td>\n",
              "      <td>381748</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>kill moon moon2N</td>\n",
              "      <td>0</td>\n",
              "      <td>kill moon moon2n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>677</th>\n",
              "      <td>0</td>\n",
              "      <td>2018-05-23T21:23:01.103Z</td>\n",
              "      <td>forsen</td>\n",
              "      <td>Raft</td>\n",
              "      <td>261172</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2$ TOP DONATOR OF THE DAY OMEGALUL 2$ TOP DONA...</td>\n",
              "      <td>1</td>\n",
              "      <td>2$ top donator of the day omegalul 2$ top dona...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd484f17-eae3-4dd4-b66c-af3d8abc4685')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd484f17-eae3-4dd4-b66c-af3d8abc4685 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd484f17-eae3-4dd4-b66c-af3d8abc4685');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      sentiment                      date      channel            game  \\\n",
              "1259          0  2018-05-22T03:21:17.481Z        xqcow       Overwatch   \n",
              "1623          1  2018-05-16T19:32:55.000Z       forsen     The Council   \n",
              "611          -1  2018-05-17T16:56:40.391Z  moonmoon_ow  Dark Souls III   \n",
              "514           1  2018-05-03T16:36:44.324Z       forsen             IRL   \n",
              "413           1  2018-05-09T04:59:17.521Z        xqcow        Fortnite   \n",
              "1075          1  2018-05-28T19:40:05.478Z   sodapoppin    Bless Online   \n",
              "538           1  2018-05-23T21:40:22.218Z       forsen            Raft   \n",
              "482           1  2018-05-30T19:02:31.082Z       forsen      Dark Souls   \n",
              "398          -1  2018-05-21T16:26:58.802Z  moonmoon_ow  Dark Souls III   \n",
              "677           0  2018-05-23T21:23:01.103Z       forsen            Raft   \n",
              "\n",
              "         user    mod  subscriber  \\\n",
              "1259  2475329  False       False   \n",
              "1623  2342940  False        True   \n",
              "611    226947  False        True   \n",
              "514      9000  False        True   \n",
              "413    295331  False       False   \n",
              "1075   322720  False        True   \n",
              "538    304456  False        True   \n",
              "482    971480  False       False   \n",
              "398    381748  False        True   \n",
              "677    261172  False       False   \n",
              "\n",
              "                                                message sentiment_relevel  \\\n",
              "1259                                                POG                 1   \n",
              "1623                                         ALLO ZULUL                 2   \n",
              "611                      I WAS DANCING TO THAT DansGame                 0   \n",
              "514   gachiBASS Clap gachiBASS Clap gachiBASS Clap g...                 2   \n",
              "413                                           gachiBASS                 2   \n",
              "1075  \"Premium Membership (180 Days)\" gives 8 in-gam...                 2   \n",
              "538                                             forsen1                 2   \n",
              "482     CURSED OMEGALUL CURSED OMEGALUL CURSED OMEGALUL                 2   \n",
              "398                                    kill moon moon2N                 0   \n",
              "677   2$ TOP DONATOR OF THE DAY OMEGALUL 2$ TOP DONA...                 1   \n",
              "\n",
              "                                        message_uncased  \n",
              "1259                                                pog  \n",
              "1623                                         allo zulul  \n",
              "611                      i was dancing to that dansgame  \n",
              "514   gachibass clap gachibass clap gachibass clap g...  \n",
              "413                                           gachibass  \n",
              "1075  \"premium membership (180 days)\" gives 8 in-gam...  \n",
              "538                                             forsen1  \n",
              "482     cursed omegalul cursed omegalul cursed omegalul  \n",
              "398                                    kill moon moon2n  \n",
              "677   2$ top donator of the day omegalul 2$ top dona...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labeled_msgs = pd.read_csv(\"./emote-controlled/data/labeled_dataset.csv\",\n",
        "                           header = 0,\n",
        "                           names  = [\"sentiment\",\n",
        "                                     \"date\",\n",
        "                                     \"channel\",\n",
        "                                     \"game\",\n",
        "                                     \"user\",\n",
        "                                     \"mod\", \t\n",
        "                                     \"subscriber\",\n",
        "                                     \"message\"])\n",
        "labeled_msgs['sentiment_relevel'] = (labeled_msgs['sentiment'] + 1).astype('category')\n",
        "labeled_msgs['message_uncased'] = labeled_msgs.message.str.lower()\n",
        "print(\"Number of labeled messages: \", labeled_msgs.shape[0])\n",
        "# Display 5 random rows from the data.\n",
        "labeled_msgs.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNj2M39oDOQT"
      },
      "source": [
        "# Load labeled Twitch emotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "DuTi6hufDUnW",
        "outputId": "4f107b31-8391-421e-d9bb-e38163804527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labeled emotes:  100\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-725fa31a-e840-466c-b785-f165a1b74b03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>word_uncased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>gachiBASS</td>\n",
              "      <td>0.38</td>\n",
              "      <td>gachibass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>OMEGALUL</td>\n",
              "      <td>0.43</td>\n",
              "      <td>omegalul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>POGGERS</td>\n",
              "      <td>0.80</td>\n",
              "      <td>poggers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>:o</td>\n",
              "      <td>0.06</td>\n",
              "      <td>:o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>TwitchUnity</td>\n",
              "      <td>0.60</td>\n",
              "      <td>twitchunity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>NotLikeThis</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>notlikethis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>DoritosChip</td>\n",
              "      <td>0.01</td>\n",
              "      <td>doritoschip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>EZ</td>\n",
              "      <td>0.58</td>\n",
              "      <td>ez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>:D</td>\n",
              "      <td>0.87</td>\n",
              "      <td>:d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Kreygasm</td>\n",
              "      <td>0.81</td>\n",
              "      <td>kreygasm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-725fa31a-e840-466c-b785-f165a1b74b03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-725fa31a-e840-466c-b785-f165a1b74b03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-725fa31a-e840-466c-b785-f165a1b74b03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           word  sentiment word_uncased\n",
              "91    gachiBASS       0.38    gachibass\n",
              "54     OMEGALUL       0.43     omegalul\n",
              "58      POGGERS       0.80      poggers\n",
              "6            :o       0.06           :o\n",
              "82  TwitchUnity       0.60  twitchunity\n",
              "53  NotLikeThis      -0.49  notlikethis\n",
              "23  DoritosChip       0.01  doritoschip\n",
              "24           EZ       0.58           ez\n",
              "3            :D       0.87           :d\n",
              "45     Kreygasm       0.81     kreygasm"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labeled_emotes = pd.read_csv(\"./emote-controlled/lexica/emote_average.tsv\",\n",
        "                             sep    = '\\t',\n",
        "                             header = 0,\n",
        "                             names  = [\"word\", \"sentiment\"])\n",
        "\n",
        "labeled_emotes[\"word_uncased\"] = labeled_emotes.word.str.lower()\n",
        "print(\"Number of labeled emotes: \", labeled_emotes.shape[0])\n",
        "# Display 10 random rows from the data.\n",
        "labeled_emotes.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIBJKdV_PnJP"
      },
      "source": [
        "# BERT Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ThwZA2628l3"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertForSentenceClassification(BertModel):\n",
        "    def __init__(self, config,\n",
        "                 use_dropout = True,\n",
        "                 ext_embed_mode = None,\n",
        "                 concat_embed_size = 0,\n",
        "                 dropout = 0.5):\n",
        "        '''\n",
        "        ext_embed_mode: ['concat', 'GRU', None]\n",
        "        add mode feeds BERT pooler output and word2vec embeddings to a GRU cell\n",
        "        '''\n",
        "        super().__init__(config)\n",
        "        \n",
        "        self.ext_embed_mode = ext_embed_mode\n",
        "\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "        if ext_embed_mode == \"GRU\":\n",
        "            # A GRU cell with layer norm\n",
        "\n",
        "            # W2V input linear layers\n",
        "            self.Wiz = nn.Linear(config.hidden_size + concat_embed_size, config.hidden_size)\n",
        "            self.Wir = nn.Linear(config.hidden_size + concat_embed_size, config.hidden_size)\n",
        "            self.Wih = nn.Linear(config.hidden_size + concat_embed_size, config.hidden_size)\n",
        "\n",
        "            self.LN = nn.LayerNorm(config.hidden_size)\n",
        "\n",
        "            # BERT ouput linear layers\n",
        "            self.Whz = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "            self.Whr = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "            self.Whh = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        if ext_embed_mode == \"concat\" or ext_embed_mode == \"both\":\n",
        "            self.concat_dense = nn.Sequential(\n",
        "                nn.Linear(in_features  = concat_embed_size,\n",
        "                          out_features = concat_embed_size),\n",
        "                nn.LayerNorm(concat_embed_size),\n",
        "                nn.GELU()\n",
        "            )\n",
        "\n",
        "        self.l1 = nn.Linear(config.hidden_size + concat_embed_size, 256)\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(256)\n",
        "\n",
        "        self.a1      = nn.SiLU() ## nn.GELU() ##nn.ReLU()\n",
        "        self.l2      =  nn.Linear(256, 128)\n",
        "\n",
        "        self.layer_norm2 = nn.LayerNorm(128)\n",
        "\n",
        "        self.a2      = nn.SiLU() #nn.GELU() ##nn.ReLU()\n",
        "        self.l3      = nn.Linear(128, config.num_labels)\n",
        "\n",
        "        self.loss = torch.nn.CrossEntropyLoss()\n",
        "        self.use_dropout = use_dropout\n",
        "\n",
        "    def forward(self,\n",
        "                labels = None,\n",
        "                ext_embed_add = None,\n",
        "                ext_embed_concat = None,\n",
        "                **kwargs):\n",
        "        '''\n",
        "        ext_embed_add: embeddings add to pooler outputs\n",
        "        ext_embed_concat: embeddings concantenated to pooler outputs\n",
        "        '''\n",
        "        outputs = super().forward(**kwargs)\n",
        "\n",
        "        cls_token_repr = outputs.pooler_output\n",
        "\n",
        "        if self.ext_embed_mode is not None:\n",
        "            if self.ext_embed_mode == \"concat\":\n",
        "                out_concat = self.concat_dense(ext_embed_concat)\n",
        "                cls_token_repr = torch.cat(\n",
        "                    (cls_token_repr, out_concat),\n",
        "                    dim = -1)\n",
        "            elif self.ext_embed_mode == \"GRU\":\n",
        "                # GRU cell\n",
        "                z = torch.sigmoid(self.LN(self.Wiz(ext_embed_add)) + self.LN(self.Whz(cls_token_repr)))\n",
        "                r = torch.sigmoid(self.LN(self.Wir(ext_embed_add)) + self.LN(self.Whr(cls_token_repr)))\n",
        "                g = torch.tanh(self.LN(self.Wih(ext_embed_add)) + self.LN(self.Whh(r * cls_token_repr)))\n",
        "                h = (1 - z) * cls_token_repr + z * g\n",
        "\n",
        "        # apply dropout\n",
        "        if self.use_dropout:\n",
        "          dropouts = self.dropout(h)\n",
        "        else:\n",
        "          dropouts = h\n",
        "\n",
        "        linear     = self.layer_norm1(self.l1(dropouts))\n",
        "        activation = self.a1(linear)\n",
        "        linear     = self.layer_norm2(self.l2(activation))\n",
        "        activation = self.a2(linear)\n",
        "        logits     = self.l3(activation)\n",
        "        if labels is not None:\n",
        "            outputs = (logits, self.loss(logits, labels))\n",
        "        else:\n",
        "            outputs = (logits,)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKMbmbGKB17K"
      },
      "source": [
        "# BERTweet Tokenisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLO9dJCqUjBX"
      },
      "source": [
        "BERTweets has its own tokenizer, so we have to repeat the data loading process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfjh0LgQB5pb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "pretrained = \"bert-base-cased\"\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(pretrained)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn9H7kxho3dI"
      },
      "source": [
        "## Prepare inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcZFS1IeUFX3"
      },
      "outputs": [],
      "source": [
        "inputs = labeled_msgs.message.values.tolist()\n",
        "MAX_LEN = max([len(bert_tokenizer(datapoint)['input_ids']) for datapoint in inputs])\n",
        "\n",
        "print(inputs)\n",
        "print(len(inputs))\n",
        "\n",
        "labels = labeled_msgs.sentiment_relevel.values\n",
        "\n",
        "tokenized_inputs = bert_tokenizer(\n",
        "    inputs,\n",
        "    add_special_tokens = True,\n",
        "    padding = 'max_length',\n",
        "    max_length = MAX_LEN,\n",
        "    return_tensors = 'pt',\n",
        ")\n",
        "\n",
        "input_ids = tokenized_inputs['input_ids']\n",
        "attention_masks = tokenized_inputs['attention_mask']\n",
        "\n",
        "messages = [message.split(' ') for message in labeled_msgs.message]\n",
        "w2vmodel = Word2Vec(sentences = messages,\n",
        "                    min_count = 1,\n",
        "                    vector_size = 768,\n",
        "                    workers = 4,\n",
        "                    window = 5,\n",
        "                    sg = 1,\n",
        "                    seed = SEED) # train further when adding new prediction data\n",
        "input_w2v = torch.Tensor(\n",
        "    [w2vmodel.wv[message].sum(axis = 0) for message in messages]\n",
        "    )\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "#print('Original: ', tokenized_inputs['input_ids'][0])\n",
        "#print('Original Content: ', labeled_msgs.message[0])\n",
        "#print(bertweet_tokenizer.convert_tokens_to_ids(bertweet_tokenizer.tokenize(labeled_msgs.message[0])))\n",
        "#print('* Token IDs:', tokenized_inputs['attention_mask'][0])\n",
        "#print('* Tokenized:', bertweet_tokenizer.decode(tokenized_inputs['input_ids'][0]))\n",
        "#print('* Attention_mask', tokenized_inputs['attention_mask'][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHhOVofjo9b-"
      },
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOvIJzaqo7To",
        "outputId": "ca288749-4f81-4d38-acb0-7cfbaa12878b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "example train_input:     tensor([  101,  1851,   152, 17145, 12412,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0])\n",
            "example attention_mask:  tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "bert_train_dataloader, bert_validation_dataloader = train_valid_split_w2v(\n",
        "    input_ids       = tokenized_inputs['input_ids'],\n",
        "    input_w2v       = input_w2v,\n",
        "    attention_masks = tokenized_inputs['attention_mask'],\n",
        "    labels          = labels,\n",
        "    batch_size      = 64\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzQYs5rbEf8G"
      },
      "source": [
        "# Load BERT-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8NXxIPF6364",
        "outputId": "9939ffc2-b492-4103-eb3e-e08598c9d49b"
      },
      "outputs": [],
      "source": [
        "model = BertForSentenceClassification.from_pretrained(\n",
        "    pretrained,\n",
        "    num_labels = 3,\n",
        "    use_dropout = True,\n",
        "    ext_embed_mode = \"add\"\n",
        "#    concat_embed_size = w2v_ext.shape[-1]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkrVxHa428l5",
        "outputId": "a85e7b48-43d7-45f2-8dbe-af583f619cf0"
      },
      "outputs": [],
      "source": [
        "# Model parameters visualization\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer Layer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "if model.ext_embed_mode == \"both\" or model.ext_embed_mode == \"concat\":\n",
        "    for p in params[-14:]:\n",
        "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "elif model.ext_embed_mode == \"add\":\n",
        "    for p in params[-6:]:\n",
        "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "else:\n",
        "    for p in params[-4:]:\n",
        "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY-mBq95RhWu"
      },
      "source": [
        "# Freeze Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4vWsnyvRs9y"
      },
      "outputs": [],
      "source": [
        "freeze_layers = [model.embeddings, *model.encoder.layer[:5]] # freeze first 4 transformer layers\n",
        "for layer in freeze_layers:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = False\n",
        "## Check if layers have been frozen\n",
        "#for param in model.embeddings.parameters():\n",
        "#    print(param.requires_grad)\n",
        "#for layer in model.encoder.layer[:5]:\n",
        "#    for param in layer.parameters():\n",
        "#        print(param.requires_grad)\n",
        "#for layer in model.encoder.layer[5:]:\n",
        "#    for param in layer.parameters():\n",
        "#        print(param.requires_grad)\n",
        "#print(list(model.encoder.named_children()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pH5FpjRRlFf"
      },
      "source": [
        "# Reinitialise Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTj-UFeqRvko"
      },
      "outputs": [],
      "source": [
        "## Reinitialise last layer\n",
        "model.encoder.layer[-6:].apply(model._init_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzTZp9neEkDh"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8yMCazi28l7"
      },
      "outputs": [],
      "source": [
        "# About 2-3 seconds per epoch using GPU\n",
        "model_eval = train_model(\n",
        "    model  = model,\n",
        "    epochs = 50,\n",
        "    train_dataloader = bert_train_dataloader,\n",
        "    validation_dataloader = bert_validation_dataloader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbVeyragOqWD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('w2v_GRU_SILU_freeze4_reinit6_epoch50_lr2e-5_wd01_batch64.json', 'w') as f:\n",
        "  json.dump(model_eval, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CYALXjB-Kan"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  os.makedirs(\"./weights/\")\n",
        "except:\n",
        "  print(\"dir exists\")\n",
        "\n",
        "model.save_pretrained(\"./weights/curr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-zghlV928l8"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_loss_and_acc(loss_vals, eval_accs):\n",
        "    sns.set(style='darkgrid')\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "    fig, ax1 = plt.subplots(1,1)\n",
        "    ax1.plot(loss_vals, 'b-o', label = 'training loss')\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(eval_accs, 'y-o', label = 'validation accuracy')\n",
        "    ax2.set_title(\"Training loss and validation accuracy\")\n",
        "    ax2.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\", color='b')\n",
        "    ax2.set_ylabel(\"Accuracy\", color='y')\n",
        "    ax1.tick_params(axis='y', rotation=0, labelcolor='b' )\n",
        "    ax2.tick_params(axis='y', rotation=0, labelcolor='y' )\n",
        "    plt.show()\n",
        "\n",
        "def plot_loss(train_loss, valid_loss):\n",
        "    # Use plot styling from seaborn.\n",
        "    sns.set(style='darkgrid')\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "    plt.plot(train_loss, 'b-o', label=\"Training\")\n",
        "    plt.plot(valid_loss, 'g-o', label=\"Validation\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_acc_and_f1(eval_accs, f1):\n",
        "    sns.set(style='darkgrid')\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "    fig, ax1 = plt.subplots(1,1)\n",
        "    ax1.plot(f1, 'g-o', label = 'training loss')\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(eval_accs, 'k-o', label = 'validation accuracy')\n",
        "    ax2.set_title(\"F1 score and Validation accuracy\")\n",
        "    ax2.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"F1 score\", color='g')\n",
        "    ax2.set_ylabel(\"Accuracy\", color='k')\n",
        "    ax1.tick_params(axis='y', rotation=0, labelcolor='g' )\n",
        "    ax2.tick_params(axis='y', rotation=0, labelcolor='k' )\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSZOHRrb28l8"
      },
      "outputs": [],
      "source": [
        "plot_loss_and_acc(model_eval[\"train_loss\"], model_eval[\"valid_accs\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH9jruByECWM"
      },
      "outputs": [],
      "source": [
        "plot_loss(model_eval[\"train_loss\"], model_eval[\"valid_loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1sp5dv1EEOg"
      },
      "outputs": [],
      "source": [
        "plot_acc_and_f1(model_eval[\"valid_accs\"], model_eval[\"f1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dliLwY3L28l9"
      },
      "outputs": [],
      "source": [
        "def predict(inputs, tokenizer, model):\n",
        "  with torch.no_grad():\n",
        "    max_len = max([len(tokenizer(datapoint)['input_ids']) for datapoint in inputs])\n",
        "    tokenized_inputs = tokenizer(\n",
        "      inputs.tolist(),          # Input text\n",
        "      add_special_tokens=True,  # add '[CLS]' and '[SEP]'\n",
        "      padding='max_length',     # pad to a length specified by the max_length\n",
        "      max_length=max_len,       # truncate all sentences longer than max_length\n",
        "      return_tensors='pt',      # return everything we need as PyTorch tensors\n",
        "    )\n",
        "    output = model(input_ids = tokenized_inputs['input_ids'])\n",
        "    output = nn.functional.softmax(output[0]).detach().numpy()\n",
        "    output = output.argmax(axis = 1)\n",
        "  return output\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "413_project_GRU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
